{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "author_id.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PJDT3u5UUVqr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Author ID Accuracy\n",
        "\n",
        "We have a set of emails, half of which were written by one person and the other half by another person at the same company . Our objective is to classify the emails as written by one person or the other based only on the text of the email. We will start with Naive Bayes in this mini-project, and then expand in later projects to other algorithms.\n",
        "\n",
        "We will start by giving you a list of strings. Each string is the text of an email, which has undergone some basic preprocessing; we will then provide the code to split the dataset into training and testing sets. \n",
        "\n",
        "One particular feature of Naive Bayes is that it’s a good algorithm for working with text classification. When dealing with text, it’s very common to treat each unique word as a feature, and since the typical person’s vocabulary is many thousands of words, this makes for a large number of features. The relative simplicity of the algorithm and the independent features assumption of Naive Bayes make it a strong performer for classifying texts. In this mini-project, you will download and install sklearn on your computer and use Naive Bayes to classify emails by author."
      ]
    },
    {
      "metadata": {
        "id": "ncGTAIeRSDza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib \n",
        "matplotlib.use('agg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "# import sklearn\n",
        "import nltk\n",
        "import urllib\n",
        "import tarfile\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from time import time\n",
        "\n",
        "# features and labels creation\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "\n",
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Decision Trees\n",
        "from sklearn import tree\n",
        "\n",
        "import pickle\n",
        "import _pickle as cPickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfMOMM-qThmA",
        "colab_type": "code",
        "outputId": "c3aa878a-7483-4ae3-ed28-d84d320ef898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-18 10:49:17--  https://www.cs.cmu.edu/~./enron/enron_mail_20150507.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 443254787 (423M) [application/x-tar]\n",
            "Saving to: ‘enron_mail_20150507.tar.gz.1’\n",
            "\n",
            "enron_mail_20150507 100%[===================>] 422.72M   856KB/s    in 8m 33s  \n",
            "\n",
            "2019-03-18 10:57:50 (844 KB/s) - ‘enron_mail_20150507.tar.gz.1’ saved [443254787/443254787]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tETgGzFtSvTe",
        "colab_type": "code",
        "outputId": "7c2c410f-985f-438c-8047-8c0ca403e19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tfile = tarfile.open(\"enron_mail_20150507.tar.gz\", \"r:gz\")\n",
        "tfile.extractall(\".\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 34s, sys: 49.3 s, total: 2min 23s\n",
            "Wall time: 2min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dL1gqcuDXMwN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sys.path.append(\"../tools/\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nJ1i_wkGgoxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv email_authors.pkl tools/email_authors.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YccOFBI_jumm",
        "colab_type": "code",
        "outputId": "f2acc2ca-7b15-441e-a1af-b2efe4071600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "original = \"tools/word_data.pkl\"\n",
        "destination = \"tools/word_data_unix.pkl\"\n",
        "\n",
        "content = ''\n",
        "outsize = 0\n",
        "with open(original, 'rb') as infile:\n",
        "    content = infile.read()\n",
        "with open(destination, 'wb') as output:\n",
        "    for line in content.splitlines():\n",
        "        outsize += len(line) + 1\n",
        "        output.write(line + str.encode('\\n'))\n",
        "\n",
        "print(\"Done. Saved %s bytes.\" % (len(content)-outsize))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done. Saved 35156 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9gB93ITMdAIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(words_file = \"tools/word_data_unix.pkl\", authors_file=\"tools/email_authors.pkl\"):\n",
        "    \"\"\" \n",
        "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
        "        and the corresponding authors (by default email_authors.pkl) and performs\n",
        "        a number of preprocessing steps:\n",
        "            -- splits into training/testing sets (10% testing)\n",
        "            -- vectorizes into tfidf matrix\n",
        "            -- selects/keeps most helpful features\n",
        "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
        "        4 objects are returned:\n",
        "            -- training/testing features\n",
        "            -- training/testing labels\n",
        "    \"\"\"\n",
        "\n",
        "    ### the words (features) and authors (labels), already largely preprocessed\n",
        "    ### this preprocessing will be repeated in the text learning mini-project\n",
        "    authors_file_handler = open(authors_file, \"rb\")\n",
        "    authors = pickle.load(authors_file_handler)\n",
        "    authors_file_handler.close()\n",
        "\n",
        "    words_file_handler = open(words_file, \"rb\")\n",
        "    word_data = pickle.load(words_file_handler)\n",
        "    words_file_handler.close()\n",
        "\n",
        "    ### test_size is the percentage of events assigned to the test set\n",
        "    ### (remainder go into training)\n",
        "    features_train, features_test, labels_train, labels_test = train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    ### text vectorization--go from strings to lists of numbers\n",
        "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
        "    features_test_transformed  = vectorizer.transform(features_test)\n",
        "\n",
        "\n",
        "\n",
        "    ### feature selection, because text is super high dimensional and \n",
        "    ### can be really computationally chewy as a result\n",
        "    selector = SelectPercentile(f_classif, percentile=10)\n",
        "    selector.fit(features_train_transformed, labels_train)\n",
        "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
        "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
        "\n",
        "    ### info on the data\n",
        "    print(\"no. of Chris training emails:\", sum(labels_train))\n",
        "    print(\"no. of Sara training emails:\", len(labels_train)-sum(labels_train))\n",
        "    \n",
        "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SAbSZFNNapf7",
        "colab_type": "code",
        "outputId": "38405428-35d4-4f1a-ea66-01edf4af736c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "### features_train and features_test are the features for the training\n",
        "### and testing datasets, respectively\n",
        "### labels_train and labels_test are the corresponding item labels\n",
        "features_train, features_test, labels_train, labels_test = preprocess()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of Chris training emails: 7936\n",
            "no. of Sara training emails: 7884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fwWTqY50WxG8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### #1 Naive Bayes"
      ]
    },
    {
      "metadata": {
        "id": "y3-w9ENAlEr8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# instantiate the classifier\n",
        "clf = GaussianNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u10KjG09lRIX",
        "colab_type": "code",
        "outputId": "6f78cb0a-4e27-41b4-a480-bcadd70cae60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train\n",
        "clf.fit(features_train, labels_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.06 s, sys: 13.9 ms, total: 1.07 s\n",
            "Wall time: 1.07 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "n-rZWxMhlfeN",
        "colab_type": "code",
        "outputId": "39bd7dd0-a56b-44b2-ac91-1036e5b69b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# predict\n",
        "pred = clf.predict(features_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 104 ms, sys: 7.62 ms, total: 112 ms\n",
            "Wall time: 117 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TX09kP-fmI79",
        "colab_type": "code",
        "outputId": "c90fdc02-6ed2-4b73-994d-38d17c8330a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(pred, labels_test)\n",
        "print('\\naccuracy = {0}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy = 0.9732650739476678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RnRPoTLkXucr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### #2 SVM"
      ]
    },
    {
      "metadata": {
        "id": "lGfvzKYMXCS8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# classifier\n",
        "clf = SVC(C=1.0, kernel='linear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ThhcxWxxZY-U",
        "colab_type": "code",
        "outputId": "f1c9155e-b005-49a3-d6ed-7c716b06bc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "t0 =time()\n",
        "# train\n",
        "clf.fit(features_train, labels_train)\n",
        "print(\"\\ntraining time:\", round(time()-t0, 3), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 268.667 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7EIfbMx2ZNbX",
        "colab_type": "code",
        "outputId": "180e8286-2a4e-4fbd-c18f-e7fd0f3f60d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "t0 = time()\n",
        "# predict\n",
        "pred = clf.predict(features_test)\n",
        "print(\"predicting time:\", round(time()-t0, 3), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicting time: 27.241 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xrPyCpn-X0bN",
        "colab_type": "code",
        "outputId": "79d4ff95-186d-4910-b903-da07d1921205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "accuracy = accuracy_score(pred, labels_test)\n",
        "print('\\naccuracy = {0}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy = 0.9840728100113766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_0NjlVDlchRc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Create a function for SVM classifier, training, predicting and calculating accuracy\n",
        "\n",
        "* it returns the predictions"
      ]
    },
    {
      "metadata": {
        "id": "O73xY_a4a3Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ml_svm(features_train, features_test, labels_train, labels_test, kernel=\"linear\", C=1.0):\n",
        "  # classifier\n",
        "  clf = SVC(kernel=kernel, C=C)\n",
        "  \n",
        "  t0 =time()\n",
        "  # train\n",
        "  clf.fit(features_train, labels_train)\n",
        "  print(\"\\ntraining time:\", round(time()-t0, 3), \"s\")\n",
        "  \n",
        "  t0 = time()\n",
        "  # predict\n",
        "  pred = clf.predict(features_test)\n",
        "  print(\"predicting time:\", round(time()-t0, 3), \"s\")\n",
        "  \n",
        "  # calculate accuracy\n",
        "  accuracy = accuracy_score(pred, labels_test)\n",
        "  print('\\naccuracy = {0}'.format(accuracy))\n",
        "  \n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d73wrLCacYga",
        "colab_type": "code",
        "outputId": "1ec0b812-7f9a-4e09-bdad-abb989879af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "pred = ml_svm(features_train, features_test, labels_train, labels_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 265.231 s\n",
            "predicting time: 27.534 s\n",
            "\n",
            "accuracy = 0.9840728100113766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4e3pC6m1czL9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Speed up an Algorithm\n",
        "* Create a smaller Training Set\n",
        "* Trade off: the accuracy goes down"
      ]
    },
    {
      "metadata": {
        "id": "gWmzSHMhceeM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one percent of the data set\n",
        "features_train = features_train[:int(len(features_train)/100)] \n",
        "labels_train = labels_train[:int(len(labels_train)/100)] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OX2gbcDzeIeM",
        "colab_type": "code",
        "outputId": "a61aec30-207d-46a6-8bf3-e7144c591929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "pred = ml_svm(features_train, features_test, labels_train, labels_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 0.139 s\n",
            "predicting time: 1.398 s\n",
            "\n",
            "accuracy = 0.8845278725824801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iM3LttMMfepN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Voice recognition and transaction blocking need to happen in real time, with almost no delay.  There's no obvious need to predict an email author instantly."
      ]
    },
    {
      "metadata": {
        "id": "68qyyzXEfoxH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Deploy an RBF Kernel\n",
        "\n",
        "Keep the training set slice code from the last quiz, so that you are still training on only 1% of the full training set. Change the kernel of your SVM to “rbf”"
      ]
    },
    {
      "metadata": {
        "id": "OZn1vuUVeTcN",
        "colab_type": "code",
        "outputId": "9c9d7e81-7f33-49cb-8e43-0aedda9ea9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "pred = ml_svm(features_train, features_test, labels_train, labels_test, kernel=\"rbf\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 0.167 s\n",
            "predicting time: 1.655 s\n",
            "\n",
            "accuracy = 0.6160409556313993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YC7Xj3w3gA8T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optimize C Parameter\n",
        "\n",
        "Keep the training set size and rbf kernel from the last quiz, but try several values of C (say, 10.0, 100., 1000., and 10000.). Which one gives the best accuracy?"
      ]
    },
    {
      "metadata": {
        "id": "MTsTq1h9f6G_",
        "colab_type": "code",
        "outputId": "3ccdd8e4-ce3b-425f-b762-c9900612b6bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "cell_type": "code",
      "source": [
        "for C in [10, 100, 1000, 10000]:\n",
        "    print('C =',C,)\n",
        "    pred = ml_svm(features_train, features_test, labels_train, labels_test, kernel='rbf', C=C)\n",
        "    print('\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C = 10\n",
            "\n",
            "training time: 0.157 s\n",
            "predicting time: 1.633 s\n",
            "\n",
            "accuracy = 0.6160409556313993\n",
            "\n",
            "\n",
            "\n",
            "C = 100\n",
            "\n",
            "training time: 0.154 s\n",
            "predicting time: 1.633 s\n",
            "\n",
            "accuracy = 0.6160409556313993\n",
            "\n",
            "\n",
            "\n",
            "C = 1000\n",
            "\n",
            "training time: 0.146 s\n",
            "predicting time: 1.553 s\n",
            "\n",
            "accuracy = 0.8213879408418657\n",
            "\n",
            "\n",
            "\n",
            "C = 10000\n",
            "\n",
            "training time: 0.144 s\n",
            "predicting time: 1.306 s\n",
            "\n",
            "accuracy = 0.8924914675767918\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "03boI_Vgge7b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Accuracy after Optimizing C\n",
        "\n",
        "The decision boundary becomes more complex."
      ]
    },
    {
      "metadata": {
        "id": "Z2wU5sZ-g-q1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optimized RBF vs Linear SVML Accuracy\n",
        "\n",
        "* What is the accuracy of the optimized SVM?"
      ]
    },
    {
      "metadata": {
        "id": "JTl3qP29gO2r",
        "colab_type": "code",
        "outputId": "18495141-02bc-4637-e539-27d00233e928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "### labels_train and labels_test are the corresponding item labels\n",
        "features_train, features_test, labels_train, labels_test = preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of Chris training emails: 7936\n",
            "no. of Sara training emails: 7884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "trgUk1wJhWss",
        "colab_type": "code",
        "outputId": "64b3af8c-8863-4001-d7c4-51b3e46970c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# optimized parameters \n",
        "pred = ml_svm(features_train, features_test, labels_train, labels_test, kernel='rbf', C=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 179.25 s\n",
            "predicting time: 20.657 s\n",
            "\n",
            "accuracy = 0.9908987485779295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mDsw37tPhuv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Extracting Predictions from an SVM\n",
        "\n",
        "What class does your SVM (0 or 1, corresponding to Sara and Chris respectively) predict for element 10 of the test set? The 26th? The 50th? (Use the RBF kernel, C=10000, and 1% of the training set."
      ]
    },
    {
      "metadata": {
        "id": "u-uwZJpehjU8",
        "colab_type": "code",
        "outputId": "da630c3d-0996-4b03-c3b2-f8b3576af3b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "elem = [10, 26, 40]\n",
        "for i in elem:\n",
        "  print(pred[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LSA5ZkkSiyJd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### How many Chris EMails Predicted\n",
        "There are over 1700 test events--how many are predicted to be in the “Chris” (1) class? "
      ]
    },
    {
      "metadata": {
        "id": "zBetWg2Vi9cs",
        "colab_type": "code",
        "outputId": "b6a985d7-aeb7-4833-a055-34b3d5cf93b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sum(pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "8-Xeptmejhb1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Final Thoughts\n",
        "\n",
        "Hopefully it’s becoming clearer what Sebastian meant when he said Naive Bayes is great for text--it’s faster and generally gives better performance than an SVM for this particular problem. Of course, there are plenty of other problems where an SVM might work better. Knowing which one to try when you’re tackling a problem for the first time is part of the art and science of machine learning. In addition to picking your algorithm, depending on which one you try, there are parameter tunes to worry about as well, and the possibility of overfitting (especially if you don’t have lots of training data).\n",
        "\n",
        "Our general suggestion is to try a few different algorithms for each problem. Tuning the parameters can be a lot of work, but just sit tight for now--toward the end of the class we will introduce you to GridCV, a great sklearn tool that can find an optimal parameter tune almost automatically.\n"
      ]
    },
    {
      "metadata": {
        "id": "RytU6jKMf_Ky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### #3 Decision Tree"
      ]
    },
    {
      "metadata": {
        "id": "PzsX_QPKiBJZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### #1 First Email DT: Accuracy\n",
        "\n",
        "* get a decision tree up and running as a classifier, setting min_samples_split=40"
      ]
    },
    {
      "metadata": {
        "id": "3ZojqjyqnffN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ml_dt(features_train, features_test, labels_train, labels_test, min_samples_split=2):\n",
        "  # classifier\n",
        "  clf = tree.DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
        "  \n",
        "  t0 =time()\n",
        "  # train\n",
        "  clf = clf.fit(features_train, labels_train)\n",
        "  print(\"\\ntraining time:\", round(time()-t0, 3), \"s\")\n",
        "  \n",
        "  t0 = time()\n",
        "  # predict\n",
        "  pred = clf.predict(features_test)\n",
        "  print(\"predicting time:\", round(time()-t0, 3), \"s\")\n",
        "  \n",
        "  # calculate accuracy\n",
        "  accuracy = accuracy_score(pred, labels_test)\n",
        "  print('\\naccuracy = {0}'.format(accuracy))\n",
        "  \n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eV4G_HphiDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "718d854a-bf34-4564-957f-faef4c6bc57f"
      },
      "cell_type": "code",
      "source": [
        "pred = ml_dt(features_train, features_test, labels_train, labels_test, min_samples_split=40)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 84.351 s\n",
            "predicting time: 0.019 s\n",
            "\n",
            "accuracy = 0.9789533560864618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3XCP7xsiZNV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### #2 What's the number of features in your data? "
      ]
    },
    {
      "metadata": {
        "id": "PyrvVTVahzHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d61fdb8f-a574-4987-aea8-62cdfd489e19"
      },
      "cell_type": "code",
      "source": [
        "features_train.shape[1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "H9iZNELxjJLx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### #3 Changing the number of features\n",
        "\n",
        "Into the `preprocess` function:\n",
        "\n",
        "`selector = SelectPercentile(f_classif, percentile=10)`\n",
        "Change percentile from 10 to 1, and rerun"
      ]
    },
    {
      "metadata": {
        "id": "sjk698O2iyvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32d7a85-4057-4f8e-97f0-7388561389f6"
      },
      "cell_type": "code",
      "source": [
        "features_train.shape[1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "379"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "gmGo48SKjpA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### #4 Select Percentile and Complexity\n",
        "\n",
        "What do you think SelectPercentile is doing? Would a large value for percentile lead to a more complex or less complex decision tree, all other things being equal? \n",
        "\n",
        "Having fewer features around means there are fewer chances for the decision tree to carve out very specific little spots when finding a decision surface.  These specific little spots (what we'd also call evidence of a high-variance result) indicate a more complex decision-making process.  So having more features doesn't usually mean you have a less complex decision tree."
      ]
    },
    {
      "metadata": {
        "id": "jzgI9fvvjxL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f59fe995-b15f-4a8e-ab0d-7cc12f81e26d"
      },
      "cell_type": "code",
      "source": [
        "pred = ml_dt(features_train, features_test, labels_train, labels_test, min_samples_split=40)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training time: 6.267 s\n",
            "predicting time: 0.003 s\n",
            "\n",
            "accuracy = 0.9670079635949943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o5W0LmyYjoCp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2f-Nm8hjjof",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}